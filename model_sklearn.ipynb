{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import yaml\n",
    "import wandb\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dense, GRU, Dropout, Conv2D, MaxPooling2D, Flatten\n",
    "from keras.models import Sequential\n",
    "from src import read_nz_file, read_jg_file, update_meta_data, split_df, aggregate_files, add_moving_window\n",
    "from sklearn.model_selection import train_test_split\n",
    "from wandb.keras import WandbCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import confusion_matrix\n",
    "# import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_preprocessing(folder, file_type: str = 'parquet'):\n",
    "    if file_type == 'parquet':\n",
    "        X_train = pd.read_parquet(f'tmp/{folder}/X_train.parquet')\n",
    "        X_test = pd.read_parquet(f'tmp/{folder}/X_test.parquet')\n",
    "        y_train = pd.read_parquet(f'tmp/{folder}/y_train.parquet')['y']\n",
    "        y_test = pd.read_parquet(f'tmp/{folder}/y_test.parquet')['y']\n",
    "    elif file_type == 'pickle':\n",
    "        with open(f'./tmp/{folder}/X_train.pickle', 'rb') as f: X_train = pickle.load(f)\n",
    "        with open(f'./tmp/{folder}/X_test.pickle', 'rb') as f: X_test = pickle.load(f)\n",
    "        with open(f'./tmp/{folder}/y_train.pickle', 'rb') as f: y_train = pickle.load(f)\n",
    "        with open(f'./tmp/{folder}/y_test.pickle', 'rb') as f: y_test = pickle.load(f)\n",
    "\n",
    "    with open(rf'./tmp/{folder}/metadata.yaml') as file:\n",
    "        settings = yaml.full_load(file)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, settings = read_preprocessing('basic_20hz_20sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_solver = 'newton-cg'\n",
    "\n",
    "wandb.login()\n",
    "run = wandb.init(\n",
    "    project=\"CDL1\",\n",
    "    entity=\"cdl1\",\n",
    "    name=\"logistic regression\",\n",
    "    config={\n",
    "        \"architecture\": \"logistic regression\",\n",
    "        \"moving_window_size\": settings['MOVING_WINDOW_SIZE'],\n",
    "        \"hz\": settings['HZ'],\n",
    "        \"step_size\": settings['STEP_SIZE'],\n",
    "        \"test_proportion\": settings['TEST_PROPORTION'],\n",
    "        \"aggregation\": settings['AGGREGATION'],\n",
    "        \"preprocessing\": settings['PREPROCESSING'],\n",
    "        \"features\": settings['FEATURES'],\n",
    "        \"solver\": my_solver\n",
    "    }\n",
    ")\n",
    "\n",
    "labels = list(set(list(y_train)))\n",
    "\n",
    "logisticRegr = LogisticRegression(random_state=0, multi_class='multinomial', penalty='none', solver='newton-cg')\n",
    "logisticRegr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logisticRegr.predict(X_test)\n",
    "y_pred_train = logisticRegr.predict(X_train)\n",
    "y_proba = logisticRegr.predict_proba(X_test)\n",
    "\n",
    "\n",
    "wandb.sklearn.plot_classifier(\n",
    "    logisticRegr, X_train, X_test, y_train, y_test, y_pred, y_proba, labels,\n",
    "    model_name='Logistic Regression', feature_names=None\n",
    ")\n",
    "\n",
    "val_acc = metrics.accuracy_score(y_pred=y_pred, y_true=y_test)\n",
    "acc = metrics.accuracy_score(y_pred=y_pred_train, y_true=y_train)\n",
    "\n",
    "wandb.log({\n",
    "    'accuracy': acc,\n",
    "    'val_accuracy': val_acc\n",
    "})\n",
    "\n",
    "run.finish()\n",
    "\n",
    "# Visualize single plot\n",
    "wandb.sklearn.plot_confusion_matrix(y_test, y_pred, labels)\n",
    "\n",
    "wandb.sklearn.plot_feature_importances(\n",
    "    logisticRegr, [\n",
    "        'gyroscope_X(rad/s)_mean', 'gyroscope_X(rad/s)_std',\n",
    "        'gyroscope_Y(rad/s)_mean', 'gyroscope_Y(rad/s)_std',\n",
    "        'gyroscope_Z(rad/s)_mean', 'gyroscope_Z(rad/s)_std',\n",
    "        'magnetometer_X(microT)_mean', 'magnetometer_X(microT)_std',\n",
    "        'magnetometer_Y(microT)_mean', 'magnetometer_Y(microT)_std',\n",
    "        'magnetometer_Z(microT)_mean', 'magnetometer_Z(microT)_std',\n",
    "        'time_since_start(ms)_mean', 'time_since_start(ms)_std',\n",
    "        'gravity_X(G)_mean', 'gravity_X(G)_std', 'gravity_Y(G)_mean',\n",
    "        'gravity_Y(G)_std', 'gravity_Z(G)_mean', 'gravity_Z(G)_std',\n",
    "        'accelerometer_X(G)_mean', 'accelerometer_X(G)_std',\n",
    "        'accelerometer_Y(G)_mean', 'accelerometer_Y(G)_std',\n",
    "        'accelerometer_Z(G)_mean', 'accelerometer_Z(G)_std',\n",
    "        'orientation_X(rad)_mean', 'orientation_X(rad)_std',\n",
    "        'orientation_Y(rad)_mean', 'orientation_Y(rad)_std',\n",
    "        'orientation_Z(rad)_mean', 'orientation_Z(rad)_std'\n",
    "    ]\n",
    ")\n",
    "\n",
    "wandb.sklearn.plot_summary_metrics(logisticRegr, X_train, X_test, y_train, y_test)\n",
    "\n",
    "wandb.sklearn.plot_learning_curve(logisticRegr, X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fhnw-ds-cdl1-sRO1VQ75",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.2 (tags/v3.10.2:a58ebcc, Jan 17 2022, 14:12:15) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b1300d74c582e433fb42e1997eddbde559ffc953ada519ef8cefa887b1cf9492"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
