{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1c95d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import yaml\n",
    "import wandb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from src import read_nz_file, read_jg_file, update_meta_data, split_df, aggregate_files, add_moving_window\n",
    "from sklearn.model_selection import train_test_split\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.convolutional import Conv1D, Conv2D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import keras\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da4d612",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_preprocessing(folder):\n",
    "    X_train = pd.read_parquet(f'tmp/{folder}/X_train.parquet')\n",
    "    X_test = pd.read_parquet(f'tmp/{folder}/X_test.parquet')\n",
    "    y_train = pd.read_parquet(f'tmp/{folder}/y_train.parquet')['y']\n",
    "    y_test = pd.read_parquet(f'tmp/{folder}/y_test.parquet')['y']\n",
    "\n",
    "    with open(rf'./tmp/{folder}/metadata.yaml') as file:\n",
    "        settings = yaml.full_load(file)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb28eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, settings = read_preprocessing('basic_20hz_20sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abaa1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#label encoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7470ab59",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1307674d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------Experiment 1-----------------------------------------------------------------------------------------------------\n",
    "#-----------------Decision tree max depth 3------------------------------------\n",
    "\n",
    "#----------1.define hyperparameters here------------------------------\n",
    "max_depth = 3\n",
    "clf_criterion = 'entropy'\n",
    "random_state = 2\n",
    "labels = y_train.unique()\n",
    "wandb_name=\"DecisionTree\"\n",
    "\n",
    "#----------2.wandb logging code /config here----------------------------\n",
    "config = {\n",
    "    \"architecture\": 'Decision tree',\n",
    "    \"moving_window_size\": settings['MOVING_WINDOW_SIZE'],\n",
    "    \"hz\": settings['HZ'],\n",
    "    \"step_size\": settings['STEP_SIZE'],\n",
    "    \"test_proportion\": settings['TEST_PROPORTION'],\n",
    "    \"aggregation\": settings['AGGREGATION'],\n",
    "    \"preprocessing\": settings['PREPROCESSING'],\n",
    "    \"features\": settings['FEATURES'],\n",
    "    \"max_depth\": max_depth,\n",
    "    \"clf_criterion\": clf_criterion,\n",
    "    \"random_state\": random_state,\n",
    "    \"labels\": labels,\n",
    "}\n",
    "run = wandb.init(entity='cdl1',project='CDL1',name = wandb_name, config = config)\n",
    "config = run.config\n",
    "\n",
    "#-----------3.model training-----------------------------------------\n",
    "# y label encoder\n",
    "le = LabelEncoder()\n",
    "y_le_train = le.fit_transform(y_train)\n",
    "y_le_test = le.fit_transform(y_test)\n",
    "\n",
    "\n",
    "#initialize model \n",
    "\n",
    "clf = tree.DecisionTreeClassifier(criterion=config.clf_criterion, \n",
    "                                  max_depth = config.max_depth, \n",
    "                                  random_state=config.random_state)\n",
    "\n",
    "# Train the model for epochs with batch_size\n",
    "clf = clf.fit(X_train, \n",
    "              y_le_train\n",
    "              )\n",
    "\n",
    "# predict on X_test and X_train\n",
    "y_pred_train = clf.predict(X_train)\n",
    "y_pred_test = clf.predict(X_test)\n",
    "y_probas = clf.predict_proba(X_test)\n",
    "\n",
    "#---------model performance on train and test dataset-----------------------\n",
    "test_accuracy = metrics.accuracy_score(y_le_test, y_pred_test)\n",
    "train_accuracy = metrics.accuracy_score(y_le_train, y_pred_train)\n",
    "\n",
    "print(\"Accuracy on train dataset:{:.2f}\".format(train_accuracy))\n",
    "print(\"Accuracy on test dataset:{:.2f}\".format(test_accuracy))\n",
    "\n",
    "\n",
    "wandb.log({\"accuracy\": train_accuracy, \"val_acc\": test_accuracy})\n",
    "\n",
    "#confusion matrix on test dataset\n",
    "cm=confusion_matrix(y_le_test, y_pred_test)\n",
    "print(\"Confusion Matrix: \\n\", cm)\n",
    "print(classification_report(y_le_test, y_pred_test ))\n",
    "\n",
    "wandb.sklearn.plot_confusion_matrix(y_le_test, y_pred_test, config.labels)\n",
    "wandb.sklearn.plot_summary_metrics(clf, X_train, y_le_train, X_test, y_le_test)\n",
    "wandb.sklearn.plot_classifier(clf, X_train, X_test, y_le_train, y_le_test, y_pred_test,y_probas,labels,model_name='Decision Tree', feature_names=None)\n",
    "\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74490284",
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "features = X_train.columns\n",
    "dot_data = tree.export_graphviz(clf, out_file = None, filled=True, rounded=True, feature_names=features, class_names = labels)\n",
    "graph=graphviz.Source(dot_data)\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b061e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clf.feature_importances_)\n",
    "np.argmax(clf.feature_importances_)\n",
    "X_train.columns[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861e212d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------Experiment 2-----------------------------------------------------------------------------------------------------\n",
    "#-------------------Decision Tree max depth 4--------------------------------------------------------------\n",
    "max_depth = 4\n",
    "clf_criterion = 'entropy'\n",
    "random_state = 41\n",
    "labels = y_train.unique()\n",
    "wandb_name = \"Decision Tree\"\n",
    "\n",
    "#----------2.wandb logging code /config here----------------------------\n",
    "config = {\n",
    "    \"architecture\": 'Decision tree',\n",
    "    \"moving_window_size\": settings['MOVING_WINDOW_SIZE'],\n",
    "    \"hz\": settings['HZ'],\n",
    "    \"step_size\": settings['STEP_SIZE'],\n",
    "    \"test_proportion\": settings['TEST_PROPORTION'],\n",
    "    \"aggregation\": settings['AGGREGATION'],\n",
    "    \"preprocessing\": settings['PREPROCESSING'],\n",
    "    \"features\": settings['FEATURES'],\n",
    "    \"max_depth\": max_depth,\n",
    "    \"clf_criterion\": clf_criterion,\n",
    "    \"random_state\": random_state,\n",
    "    \"labels\": labels,\n",
    "}\n",
    "run = wandb.init(entity='cdl1',project='CDL1',name = wandb_name, config = config)\n",
    "config = run.config\n",
    "\n",
    "\n",
    "#-----------3.model training-----------------------------------------\n",
    "# y label encoder\n",
    "le = LabelEncoder()\n",
    "y_le_train = le.fit_transform(y_train)\n",
    "y_le_test = le.fit_transform(y_test)\n",
    "\n",
    "\n",
    "#initialize model \n",
    "\n",
    "clf = tree.DecisionTreeClassifier(criterion=config.clf_criterion, \n",
    "                                    max_depth = config.max_depth, \n",
    "                                    random_state=config.random_state)\n",
    "\n",
    "# Train the model for epochs with batch_size\n",
    "clf = clf.fit(X_train, \n",
    "                y_le_train\n",
    "                )\n",
    "\n",
    "# predict on X_test and X_train\n",
    "y_pred_train = clf.predict(X_train)\n",
    "y_pred_test = clf.predict(X_test)\n",
    "\n",
    "#---------model performance on train and test dataset-----------------------\n",
    "test_accuracy = metrics.accuracy_score(y_le_test, y_pred_test)\n",
    "train_accuracy = metrics.accuracy_score(y_le_train, y_pred_train)\n",
    "\n",
    "wandb.log({\"accuracy\": train_accuracy, \"val_acc\": test_accuracy})\n",
    "\n",
    "#confusion matrix on test dataset\n",
    "cm=confusion_matrix(y_le_test, y_pred_test)\n",
    "print(\"Confusion Matrix: \\n\", cm)\n",
    "print(classification_report(y_le_test, y_pred_test ))\n",
    "print(\"Accuracy on train dataset:{:.2f}\".format(train_accuracy))\n",
    "print(\"Accuracy on test dataset:{:.2f}\".format(test_accuracy))\n",
    "\n",
    "wandb.sklearn.plot_confusion_matrix(y_le_test, y_pred_test, config.labels)\n",
    "\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da019e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "features = X_train.columns\n",
    "dot_data = tree.export_graphviz(clf, out_file = None, filled=True, rounded=True, feature_names=features, class_names = labels)\n",
    "graph=graphviz.Source(dot_data)\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4323089",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd9befb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------Experiment 1-----------------------------------------------------------------------------------------------------\n",
    "#-----------------Random Forest classification Model------------------------------------\n",
    "\n",
    "random_state = 45\n",
    "labels = y_train.unique()\n",
    "wandb_name = \"Random Forest\"\n",
    "n_estimators = 1000                  #number of trees in the forest\n",
    "clf_criterion = 'entropy'           #function to measure quality of split /possible options- gini, log_loss, entropy\n",
    "n_jobs = 10                       #number of jobs to run in parallel\n",
    "\n",
    "#----------2.wandb logging code /config here----------------------------\n",
    "\n",
    "config = {\n",
    "    \"architecture\": 'Random Forest',\n",
    "    \"moving_window_size\": settings['MOVING_WINDOW_SIZE'],\n",
    "    \"hz\": settings['HZ'],\n",
    "    \"step_size\": settings['STEP_SIZE'],\n",
    "    \"test_proportion\": settings['TEST_PROPORTION'],\n",
    "    \"aggregation\": settings['AGGREGATION'],\n",
    "    \"preprocessing\": settings['PREPROCESSING'],\n",
    "    \"features\": settings['FEATURES'],\n",
    "    \"clf_criterion\": clf_criterion,\n",
    "    \"random_state\": random_state,\n",
    "    \"labels\": labels,\n",
    "    \"n_jobs\": n_jobs,\n",
    "    \"n_estimators\": n_estimators,\n",
    "}\n",
    "run = wandb.init(entity = 'cdl1',project='CDL1',name = wandb_name, config = config)\n",
    "config = run.config\n",
    "\n",
    "#-----------3.model training-----------------------------------------\n",
    "# y label encoder\n",
    "le = LabelEncoder()\n",
    "y_le_train = le.fit_transform(y_train) #label encoded ytrain\n",
    "y_le_test = le.fit_transform(y_test)  #label encoded ytest\n",
    "\n",
    "#model\n",
    "rf_mdl = RandomForestClassifier(n_estimators=n_estimators, n_jobs=config.n_jobs, criterion=config.clf_criterion)\n",
    "rf_mdl.fit(X_train, y_le_train)\n",
    "\n",
    "#predict\n",
    "y_pred = rf_mdl.predict(X_test)\n",
    "y_probs = rf_mdl.predict_proba(X_test)\n",
    "\n",
    "#accuracy\n",
    "test_accuracy = metrics.accuracy_score(y_le_test, y_pred)\n",
    "\n",
    "wandb.log({ \"val_acc\": test_accuracy})\n",
    "\n",
    "#confusion matrix on test dataset\n",
    "cm=confusion_matrix(y_le_test, y_pred)\n",
    "print(\"Confusion Matrix: \\n\", cm)\n",
    "print(classification_report(y_le_test, y_pred ))\n",
    "\n",
    "print(\"Accuracy on test dataset:{:.2f}\".format(test_accuracy))\n",
    "\n",
    "#wand plots\n",
    "wandb.sklearn.plot_confusion_matrix(y_le_test, y_pred, config.labels)\n",
    "#wandb.sklearn.plot_class_proportions(y_le_train, y_le_test, labels) #plots the distribution of target classes in training & test sets. \n",
    "#wandb.sklearn.plot_roc(y_le_test, y_probs, labels) #plots true positive rate(y-axis) vs false positive rate(x-axis)\n",
    "#wandb.sklearn.plot_precision_recall(y_le_test, y_probs, labels) #tradeoff between precision and recall for different thresholds.\n",
    "\n",
    "run.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1cd4ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
