{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from src import read_nz_file, read_jg_file, update_meta_data, split_df, aggregate_files, add_moving_window\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "processed data - intermediate step\n",
    "\n",
    "> raw data\n",
    "\n",
    "> clean data\n",
    "\n",
    "> preprocess data : store it in DB (better compared to file format) \n",
    "\n",
    "    - data lake\n",
    "    \n",
    "    or\n",
    "    \n",
    "    - DB model based SQL (Nice to have but not required if we deceide to save the data as a Feather file)\n",
    "\n",
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and clean raw data\n",
    "\n",
    "files from SensorLog iOS app has in total over 70 colums and precision of 12 decimal figures. The output file is over 135 MB, which is too large for GitHub. GitHub restricts the file size, therefore these files from SensorLog must be cleaned.\n",
    "\n",
    "Below summary of steps which is done only for iOS files:\n",
    "\n",
    "- read raw data as csv files\n",
    "- remove unnecessary columns (captured in list 'remove_cols' below)\n",
    "- round to 6 decimal places to reduce the size of files\n",
    "- output dataframe as csv\n",
    "- upload the csv on GitHub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Meta data\n",
    "\n",
    "The data on different data files is captured in meta dataframe below:\n",
    "- file name\n",
    "- user (nz or jg)\n",
    "- activity (running/cycling/walking/sitting)\n",
    "- pocket (in which pocket handy was during the activity)\n",
    "- position_x\n",
    "- position_y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. View data\n",
    "\n",
    "Sensor activity data is captured from 2 different Apps:\n",
    "- SensorLog (iOS) by user 'nz'\n",
    "- AndrioSensor (Andriod) by user 'jg'\n",
    "\n",
    "**Response**: 'Acivity' with 4 classes: running/walking/cycling/sitting\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_meta_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.read_csv('data/meta.csv')\n",
    "meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train = pd.DataFrame()\n",
    "test = pd.DataFrame()\n",
    "\n",
    "\n",
    "for file, user, activity in zip(meta['file'], meta['user'], meta['activity']):\n",
    "    if user == 'nz':\n",
    "        df = read_nz_file(file, activity)\n",
    "\n",
    "    elif user == 'jg':\n",
    "        df = read_jg_file(file, activity)\n",
    "\n",
    "    print(file, user, activity, df.shape)\n",
    "\n",
    "    # create synthetic features\n",
    "\n",
    "    # split into train-test\n",
    "    hz = 20\n",
    "    my_train_files, my_test_files = split_df(df, hz = hz, test_proportion = 0.2)\n",
    "\n",
    "    print(f'Train: {[len(i) for i in my_train_files]}')\n",
    "    print(f'Test: {[len(i) for i in my_test_files]}')\n",
    "\n",
    "    # aggregate data points (try moving average) transform to mean, sd, ...\n",
    "    for i, (v_train, v_test) in enumerate(zip(my_train_files, my_test_files)):\n",
    "        # i.reset_index(drop = True)\n",
    "        v_train = add_moving_window(v_train, hz_old_data = hz, seconds = 20, step_size = 20)\n",
    "        my_train_files[i] = v_train\n",
    "\n",
    "        v_test = add_moving_window(v_test, hz_old_data = hz, seconds = 20, step_size = 20)\n",
    "        my_test_files[i] = v_test\n",
    "\n",
    "    print(f'Train: {[len(i) for i in my_train_files]}')\n",
    "    print(f'Test: {[len(i) for i in my_test_files]}')\n",
    "\n",
    "    # append to train and test\n",
    "    train = aggregate_files(my_train_files, train)\n",
    "    test = aggregate_files(my_test_files, test)\n",
    "\n",
    "# X - y split for train and test data, shuffle data!?\n",
    "\n",
    "# TODO: Fix train test split to give us 80 / 20 ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "b1300d74c582e433fb42e1997eddbde559ffc953ada519ef8cefa887b1cf9492"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
