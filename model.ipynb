{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import yaml\n",
    "import wandb\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dense, GRU, Dropout, Conv2D, MaxPooling2D, Flatten\n",
    "from keras.models import Sequential\n",
    "from src import read_nz_file, read_jg_file, update_meta_data, split_df, aggregate_files, add_moving_window\n",
    "from sklearn.model_selection import train_test_split\n",
    "from wandb.keras import WandbCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_preprocessing(folder, file_type: str = 'parquet'):\n",
    "    if file_type == 'parquet':\n",
    "        X_train = pd.read_parquet(f'tmp/{folder}/X_train.parquet')\n",
    "        X_test = pd.read_parquet(f'tmp/{folder}/X_test.parquet')\n",
    "        y_train = pd.read_parquet(f'tmp/{folder}/y_train.parquet')['y']\n",
    "        y_test = pd.read_parquet(f'tmp/{folder}/y_test.parquet')['y']\n",
    "    elif file_type == 'pickle':\n",
    "        with open(f'./tmp/{folder}/X_train.pickle', 'rb') as f: X_train = pickle.load(f)\n",
    "        with open(f'./tmp/{folder}/X_test.pickle', 'rb') as f: X_test = pickle.load(f)\n",
    "        with open(f'./tmp/{folder}/y_train.pickle', 'rb') as f: y_train = pickle.load(f)\n",
    "        with open(f'./tmp/{folder}/y_test.pickle', 'rb') as f: y_test = pickle.load(f)\n",
    "\n",
    "    with open(rf'./tmp/{folder}/metadata.yaml') as file:\n",
    "        settings = yaml.full_load(file)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, settings = read_preprocessing('basic_20hz_20sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import confusion_matrix\n",
    "# import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recode CLASS to integer: LinearRegression does not take string\n",
    "def Classification(CLASS):\n",
    "    if CLASS == 'sitting':\n",
    "        return 1\n",
    "    elif CLASS == 'walking':\n",
    "        return 2\n",
    "    elif CLASS == 'running':\n",
    "        return 3\n",
    "    elif CLASS == 'cycling':\n",
    "        return 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train = y_train.apply(Classification)\n",
    "# y_test = y_test.apply(Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_solver = 'newton-cg'\n",
    "\n",
    "wandb.login()\n",
    "run = wandb.init(\n",
    "    project=\"CDL1\",\n",
    "    entity=\"cdl1\",\n",
    "    name=\"logistic regression\",\n",
    "    config={\n",
    "        \"architecture\": \"logistic regression\",\n",
    "        \"moving_window_size\": settings['MOVING_WINDOW_SIZE'],\n",
    "        \"hz\": settings['HZ'],\n",
    "        \"step_size\": settings['STEP_SIZE'],\n",
    "        \"test_proportion\": settings['TEST_PROPORTION'],\n",
    "        \"aggregation\": settings['AGGREGATION'],\n",
    "        \"preprocessing\": settings['PREPROCESSING'],\n",
    "        \"features\": settings['FEATURES'],\n",
    "        \"solver\": my_solver\n",
    "    }\n",
    ")\n",
    "\n",
    "labels = list(set(list(y_train)))\n",
    "\n",
    "logisticRegr = LogisticRegression(random_state=0, multi_class='multinomial', penalty='none', solver='newton-cg')\n",
    "logisticRegr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logisticRegr.predict(X_test)\n",
    "y_pred_train = logisticRegr.predict(X_train)\n",
    "y_proba = logisticRegr.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.sklearn.plot_classifier(\n",
    "    logisticRegr, X_train, X_test, y_train, y_test, y_pred, y_proba, labels,\n",
    "    model_name='Logistic Regression', feature_names=None\n",
    ")\n",
    "\n",
    "val_acc = metrics.accuracy_score(y_pred=y_pred, y_true=y_test)\n",
    "acc = metrics.accuracy_score(y_pred=y_pred_train, y_true=y_train)\n",
    "\n",
    "wandb.log({\n",
    "    'accuracy': acc,\n",
    "    'val_accuracy': val_acc\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize single plot\n",
    "wandb.sklearn.plot_confusion_matrix(y_test, y_pred, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.sklearn.plot_feature_importances(\n",
    "    logisticRegr, [\n",
    "        'gyroscope_X(rad/s)_mean', 'gyroscope_X(rad/s)_std',\n",
    "        'gyroscope_Y(rad/s)_mean', 'gyroscope_Y(rad/s)_std',\n",
    "        'gyroscope_Z(rad/s)_mean', 'gyroscope_Z(rad/s)_std',\n",
    "        'magnetometer_X(microT)_mean', 'magnetometer_X(microT)_std',\n",
    "        'magnetometer_Y(microT)_mean', 'magnetometer_Y(microT)_std',\n",
    "        'magnetometer_Z(microT)_mean', 'magnetometer_Z(microT)_std',\n",
    "        'time_since_start(ms)_mean', 'time_since_start(ms)_std',\n",
    "        'gravity_X(G)_mean', 'gravity_X(G)_std', 'gravity_Y(G)_mean',\n",
    "        'gravity_Y(G)_std', 'gravity_Z(G)_mean', 'gravity_Z(G)_std',\n",
    "        'accelerometer_X(G)_mean', 'accelerometer_X(G)_std',\n",
    "        'accelerometer_Y(G)_mean', 'accelerometer_Y(G)_std',\n",
    "        'accelerometer_Z(G)_mean', 'accelerometer_Z(G)_std',\n",
    "        'orientation_X(rad)_mean', 'orientation_X(rad)_std',\n",
    "        'orientation_Y(rad)_mean', 'orientation_Y(rad)_std',\n",
    "        'orientation_Z(rad)_mean', 'orientation_Z(rad)_std'\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.sklearn.plot_summary_metrics(logisticRegr, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.sklearn.plot_learning_curve(logisticRegr, X_train, y_train)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train_2 = y_train.apply(lambda x: 1 if x == 'cycling' else 0)\n",
    "# y_test_2 = y_test.apply(lambda x: 1 if x == 'cycling' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, settings = read_preprocessing('NN_5hz_5sec', file_type='pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_train_indexes = [i for i in range(0, y_train.shape[0] - 1)]\n",
    "random.shuffle(my_train_indexes)\n",
    "\n",
    "my_test_indexes = [i for i in range(0, y_test.shape[0] - 1)]\n",
    "random.shuffle(my_test_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.take(my_train_indexes, 0)\n",
    "y_train = y_train.take(my_train_indexes, 0)\n",
    "X_test = X_test.take(my_test_indexes, 0)\n",
    "y_test = y_test.take(my_test_indexes, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login()\n",
    "\n",
    "run = wandb.init(\n",
    "    project=\"CDL1\",\n",
    "    entity=\"cdl1\",\n",
    "    name=\"CNN\",\n",
    "    config={\n",
    "        \"architecture\": \"CNN\",\n",
    "        \"moving_window_size\": settings['MOVING_WINDOW_SIZE'],\n",
    "        \"hz\": settings['HZ'],\n",
    "        \"step_size\": settings['STEP_SIZE'],\n",
    "        \"test_proportion\": settings['TEST_PROPORTION'],\n",
    "        \"aggregation\": settings['AGGREGATION'],\n",
    "        \"preprocessing\": settings['PREPROCESSING'],\n",
    "        \"features\": settings['FEATURES'],\n",
    "        'batch size': 32,\n",
    "        \"epochs\": 20\n",
    "    }\n",
    ")\n",
    "\n",
    "config = wandb.config\n",
    "\n",
    "# initialize model\n",
    "model = Sequential()\n",
    "model.add(GRU(32, dropout=0.2, recurrent_dropout=0.2, input_shape=(None, X_train.shape[-1])))\n",
    "model.add(Dense(4, input_shape = (None, X_train.shape[-1]), activation = 'softmax'))\n",
    "model.summary()\n",
    "\n",
    "# compile model\n",
    "model.compile(\n",
    "    loss = 'categorical_crossentropy',\n",
    "    optimizer = 'rmsprop',\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    x = X_train,\n",
    "    y = y_train,\n",
    "    epochs = config['epochs'],\n",
    "    batch_size=config['batch size'],\n",
    "    validation_data = (X_test, y_test),\n",
    "    callbacks=[WandbCallback()]\n",
    ")\n",
    "\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(predictions.T[0]).apply(lambda x: 1 if x >= 0.5 else 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fhnw-ds-cdl1-sRO1VQ75",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b1300d74c582e433fb42e1997eddbde559ffc953ada519ef8cefa887b1cf9492"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
